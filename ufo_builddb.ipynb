{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import psycopg2\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, './text2num/')\n",
    "import text2num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ufo_nosummary.pkl\",\"r\") as pf:\n",
    "    d = pickle.load(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Make into pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([d[\"city\"],d[\"title\"],d[\"shape\"],d[\"duration\"],d[\"state\"],d[\"link\"],d[\"date\"]])\n",
    "df = df.transpose()\n",
    "df.columns = ['city','title','shape','duration','state','link','date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shapes(x):\n",
    "    dic = {\"triangular\":\"triangle\",\"triange\":\"triangle\",\"round\":\"circle\",\n",
    "           \"changed\":\"changing\",\"pyramid\":\"triangle\",\"flare\":\"light\",\n",
    "           \"dome\":\"disk\",\"hexagon\":\"other\",\"crescent\":\"other\",\"delta\":\"chevron\"}\n",
    "    if x in dic.keys():\n",
    "        return dic[x]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['shape'] = df['shape'].map(lambda x: shapes(x.lower()) if x else \"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_dt(dateStr):\n",
    "    for fmt in [\"%m/%d/%y\",\"%m/%d/%y %H:%M\"]:\n",
    "        try:\n",
    "            return datetime.strptime(dateStr, fmt)\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not using\n",
    "\n",
    "def date_only(x):\n",
    "    reg_date = \"\\d{1,2}\\/\\d{1,2}\\/\\d{2}\"\n",
    "    result = re.findall(reg_date,str(x))\n",
    "    if len(result)>0:\n",
    "        return datetime.strptime(result[0], \"%m/%d/%y\")\n",
    "    else:\n",
    "        return \"None\"\n",
    "def time_only(x):\n",
    "    reg_time = \"\\d{2}\\:\\d{2}\"\n",
    "    result = re.findall(reg_time,str(x))\n",
    "    if len(result)>0:\n",
    "        return datetime.strptime(result[0], \"%H:%M\")\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date_datetime'] = df['date'].map(lambda x: standardize_dt(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day']=df['date_datetime'].map(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertTime(elem):  \n",
    "    t = 1\n",
    "    lower = elem.lower()\n",
    "    #TODO: learn regex\n",
    "    split = elem.replace(\"-\",\" \").replace(\"s\",\" s\").replace(\"h\",\" h\").replace(\"m\",\" m\").replace(\":00\",\" min \").replace(\"00:\",\" \").replace(\"~\",\" \").replace(\"_\",\" \").replace(\"+\",\" \").replace(\"<\",\" \").replace(\">\",\" \").split(\" \")\n",
    "    num = np.mean([float(s) for s in split if s.replace(\".\", \"\",1).isdigit()])\n",
    "    if \"minutes\" in lower or \"minute\" in lower or \"min\" in lower or \"mins\" in lower or \"m \" in lower:\n",
    "    #if \"m \" in split:\n",
    "        t = 60\n",
    "    elif \"hours\" in lower or \"hour\" in lower or \"hrs\" in lower or \"hr\" in lower or \"h \" in lower:\n",
    "    #elif \"h \" in split:\n",
    "        t = 3600\n",
    "    #times.append(num*t)\n",
    "    if np.isnan(num)==False:\n",
    "        return num*t\n",
    "    if np.isnan(num)==True:\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#twice as fast as my code :(\n",
    "def infer_duration_in_seconds(text):\n",
    "    # try different regexps to extract the total seconds\n",
    "    metric_text = [\"hour\",\"minute\",\"second\",\"sec\",\"segundo\",\"min\",\"hr\",\" m\",\" h\",\" s\"]\n",
    "    metric_seconds = [3600,60,1,1,1,60,3600,60,3600,1]\n",
    "    text_replaced = text.replace(\":\",\" min \").replace(\"+\",\"\").replace(\"-\",\" \").lower() #check for colon\n",
    "    \n",
    "    #digit and metric together\n",
    "    for metric,mult in zip(metric_text,metric_seconds):\n",
    "        regex = \"\\s*(\\d+)\\+?\\s*{}s?\".format(metric)\n",
    "        res = re.findall(regex,text_replaced)\n",
    "        if len(res)>0:\n",
    "            return int(float(res[0]) * mult)\n",
    "        \n",
    "    #only metric\n",
    "    for metric,mult in zip(metric_text,metric_seconds):\n",
    "        metric_regex = \"\\s*\\+?\\s*{}\\s?\".format(metric)\n",
    "        res = re.findall(metric_regex,text_replaced)\n",
    "        if len(res)>0:\n",
    "            return mult\n",
    "    \n",
    "    #only digit (seconds)\n",
    "    dig_regex = \"\\s*(\\d+)\\+?\\s*?\"\n",
    "    res = re.findall(dig_regex,text_replaced)\n",
    "    if len(res)>0:\n",
    "        return int(float(res[0]) * 1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14482498169\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "df['duration_seconds'] = df['duration'].map(lambda x: infer_duration_in_seconds(x))\n",
    "print time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                   0\n",
       "title                  0\n",
       "shape                  0\n",
       "duration               0\n",
       "state                  0\n",
       "link                   0\n",
       "date                   0\n",
       "date_datetime        242\n",
       "duration_seconds    6306\n",
       "geo                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Link col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['link_no_ext'] = df['link'].map(lambda x: x[:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#full df\n",
    "df = pd.read_csv(\"ufo_nosummary.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "#unique geocodes\n",
    "df_geocodes = pd.read_csv(\"geocodes_8973.csv\")\n",
    "del df_geocodes['Unnamed: 0']\n",
    "df_geocodes.drop_duplicates(subset=['city','state'],inplace=True)\n",
    "df_geocodes = df_geocodes.reset_index(drop=True)\n",
    "\n",
    "#split lat/long\n",
    "df_test = pd.DataFrame(df_geocodes.latlong.str.split(',',1).tolist(),\n",
    "                                   columns = ['lat','long'])\n",
    "df_test['lat'] = df_test['lat'].map(lambda x: x[1:])\n",
    "df_test['long'] = df_test['long'].map(lambda x: x[:-1])\n",
    "del df_geocodes['latlong']\n",
    "\n",
    "#unique geocodes with lat/long separated\n",
    "df_5359_unique = pd.concat([df_geocodes,df_test],axis=1)\n",
    "\n",
    "#full df merged with unique geocodes, geocodes 56476!\n",
    "df_56476 = pd.merge(df,df_5359_unique,how='inner',on=['city','state'])\n",
    "\n",
    "#full df merged with unique geocodes, geocodes includes NaNs\n",
    "df_56476_full = pd.merge(df,df_5359_unique,how='outer',on=['city','state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###See df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###To csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99477"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full\n",
    "len(df_56476_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56476"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geocoded\n",
    "len(df_56476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19120"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not geocoded\n",
    "#where both city and state are complete\n",
    "len(not_yet_geocoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23155"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_states_notgeo = df_56476_full[df_56476_full['lat'].isnull()][['city','state']].drop_duplicates()\n",
    "len(city_states_notgeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_yet_geocoded = city_states_notgeo[city_states_notgeo['city'].isnull()==False].reset_index(drop=True)\n",
    "not_yet_geocoded = not_yet_geocoded[not_yet_geocoded['state'].isnull()==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_yet_geocoded.to_csv(\"19120_not_geocoded.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
